## R script for SAARA (Statistical Analysis of Acetylene Reduction Assay)
## To be embedded in a C++ overlay
##
## Autor : Quentin Nicoud
## Date of : 09.05.2019
## R version : 3.5.2
## List of needed packages :
##      - readxl 1.3.1
##      - xlsx 0.6.1
##      - car 3.0-2
##      - testit 0.9
##      - RInside 0.2.15
##
## Layout :
##      1 - Set up initial parameters
##      2 - Extract data from the tree generated by the Agilent software
##      3 - Transform raw data into processed data
##              i.e. pA.s-1 into mmolC2H4
##              An output table can be generated at this point
##      4 - If asked by  user the program can go further and propose to make the statistical analysis
##      5 - At last, a gaphical preview of the dat can be displayed (not sure if it will be implemented)
##
## List of functions :
##

## TO DO LIST :
#
#   Remark : For the embedding to options are available. One is to embed the R script into Qt using RInside.
#                   The other is to build the Qt with R using the bioconductor package qtbase (found out that is not compatible with this R version)
#   Other alternative for the embedding, SHINY !!! I think that I will do a first version using shiny.
#
#   In C++
#       - code the GUI using Qt
#       - add a save config function that generates an .xml or .config or .ini ? 
#
#   In R
#       - Re-write the code on data statistical analysis
#       - Add varaible neccessary to the communication between R and C++
#       - Add assertion and try
#       - DONE: include tests on the number of arguments given to each fnctions usin 'nargs()'
#       - DONE: Find a way to maintain versions of packages and to transmit R with the application. --> devtools package
#       - add the nodule mass and/or weight and the vial volume in the template to be used in the different functions.
#       - template is set up with no header. should that be added for an esaier usage of the program ?
#       - remove package mannagement from all function as I added load_SAARA_packages an unload_SAARA_packages

rm(list = ls())

#### PACKAGE MANAGEMENT AND IMPORTANT VARIABLES --------------------------------------------------------------------------------------------------------------------------------------------------------------

# Variable that should recieve input from the C++ programm
normalityThreshold <- 0.05
varHThreshold <- 0.05
poolData <- FALSE ##TRUE = testing several mutants OR repetition ##FALSE = kinetics
isKinetics <- FALSE
splitV <- 5
custom_formula <- 0
slope <- 495

list_of_required_pckg <- data.frame(pckg = c("readxl", "xlsx", "openxlsx", "car", "testit", "RInside"), 
                                    version = c("1.3.1", "0.6.1", "4.1.0.1","3.0-2", "0.9", "0.2.15"), stringsAsFactors = FALSE)

load_SAARA_packages <- function(list_of_required_pckg)
{

    ## Install and/or load packages required in the analysis.
    ## First, it tries to use devtools to install packages versions that were used duing the developpement of this script.
    ## Then it checks if every pacakges are indeed loaded, if not anyLib will install the last verion.
    ##
    ## Usage :
    ##          output <- load_SAARA_packages(list_of_required_ pckg)
    #
    ## Intput :
    ##      - list_of_required_pckg:    a list of two component. Fisrt the list of packages to be installed and then the list of versions 
    ##                                  in the same order as the list of packages that specifies in which version each package should be installed.
    ##
    ## Output :
    ##      - are_pckg_loaded:          a vector containing logical values that specifies if each package could be loaded. Values are in the same order
    ##                                  than in the list_of_required_pckg.
    
    # Test if at least one argument is given to the function
    if (nargs() < 1) {
        stop("argument 'list_of_required_pckg' is missing, with no default.")
    }
    
    # If needed install devtools, otherwise, load it. Required for installing packages with a specific version (install_version function)
    if(!require(devtools))
    {
        install.packages("devtools", dependencies = TRUE)
        
        library(devtools)
    }
    
    # If needed install installR, otherwise load it. Required for installing Rtools which is needed to compile packages from source (install_version function)
    if(!require(installr))
    {
        install.packages("installr", dependencies = TRUE)
        
        library(installr)
    }
    
    if (install.rtools(check = TRUE))
        install.rtools()
    
    # # Run through every required package
    # for ( i in 1:dim(list_of_required_pckg)[1])
    # {
    #     print(list_of_required_pckg$pckg[i])
    #     # If required, install it at the right version
    #     if (!require(list_of_required_pckg$pckg[i]))
    #     {
    #         devtools::install_version(list_of_required_pckg$pckg[i], version = list_of_required_pckg$version[i], upgrade = "never")
    #         
    #         library(list_of_required_pckg$pckg[i], character.only = TRUE)
    #     }
    # }
    
    # Run through every required package
    for ( i in 1:dim(list_of_required_pckg)[1]) {
        print(paste("Trying to install ", list_of_required_pckg$pckg[i]))
        # If required, install it at the right version
        if (!require(list_of_required_pckg$pckg[i], character.only = TRUE)) {
            tryCatch( 
                expr = {
                    devtools::install_version(list_of_required_pckg$pckg[i], version = list_of_required_pckg$version[i], dependencies = TRUE, upgrade = "never", quiet = TRUE)
                },
                    
                error = function(err) {
                    # Error handler
                    print(paste("ERROR_CAUGHT: ", err))
                },
                
                finally = {}
            )
            
            test <- require(list_of_required_pckg$pckg[i], character.only = TRUE)
            if (!test) {
                print(paste("devtools:install_version failed to install ", list_of_required_pckg$pckg[i], ", version: ", list_of_required_pckg$version[i], "."))
                print("AnyLib will try to install the latest available version for this package.")
            }
        
            else
                print(paste(list_of_required_pckg$pckg[i], " was successfully installed and loaded!"))
            
        }
    }
    
    # Then, use anylib to check the installation was successfull. If not it will install the newest version.
    if(!require(anyLib))
    {
        install.packages("anyLib", dependencies = TRUE)
        
        library(anyLib)
    }
    #Store the vector containing a booleean value that specifies if the package is loaded or not.
    are_pckgs_loaded <- anyLib::anyLib(list_of_required_pckg[[1]])
    
    # Return this value
    are_pckgs_loaded
    
   
    # new_pckg <- list_of_required_pckg$pckg[!(list_of_required_pckg$pckg %in% installed.packages()[, "Package"])]
    # if (length(new_pckg))
    # {
    #     new_pckg_ids <- which(list_of_required_pckg$pckg %in% new_pckg)
    #     for (i in 1:length(new_pckg))
    #     {
    #         tryCatch( expr = { 
    #             devtools::install_version(new_pckg[i], list_of_required_pckg$version[new_pckg_ids[i]], dependencies = TRUE)
    #             library(new_pckg[i])},
    #             
    #             error = function(err) {
    #                 #Warning handler
    #                 print(paste("ERROR_CAUGHT: ", err))},
    #             
    #             finally = {
    #                 install.packages(new_pckg[i])
    #                 library(new_pckg[i])}
    #         )
    #     }
    # }
    # 
    # remaining_pckgs <- which(!(list_of_required_pckg$pckg %in% new_pckg))
    # for (i in remaining_pckgs)
    # {
    #     require(list_of_required_pckg$pckg[i])
    # }
    
} # Seems to work on my computer

check_SAARA_packages <- function(list_of_required_pckg, are_pckgs_loaded)
{
    # Test if the arguments are given to the function
    if (nargs() < 2) {
        stop("arguments 'list_of_required_pckg' or/and 'are_pckgs_loaded' are missing, with no default.")
    }
    
    lacking_pckgs <- list_of_required_pckg$pckg[which(!are_pckgs_loaded)]
    
    if (any(!are_pckgs_loaded)) {
        print("The following packages were unable to be installed:")
        print(paste(lacking_pckgs, sep = ", "))
    }
    else { print("All packages were succesfully installed and loaded!") }
    
    if (!is.null(lacking_pckgs)) {
        for (i in lacking_pckgs) {
            if (i == "readxl")
                print("readxl could not be loaded/installed. This is critical for SAARA as it is necessary to read your data. Please fix this manually from your R console, helping with the troubleshooting page of this program. #addURL")
            
            if (i == "xlsx")
                print("xlsx could not be loaded/installed. This package is required to save the processed data. This functionnality won't be available. If it is required you can copy/paste manually. Otherwise, please fix this manually from your R console, helping with the troubleshooting page of this program. #addURL")
            
            if (i == "openxlsx")
                print("openxlsx could not be loaded/installed. This package is required by car and sometimes don't get properly installed. If not present, you should also get the error message related to car. Refer to the mentionned message for further informations.")
            
            if (i == "car")
                print("car could not be loaded/installed. This package is required for the statistical analysis of your data. This functionnality won't be available. If it is required, please fix this manually from your R console, helping with the troubleshooting page of this program. #addURL")
            ## Add the rest of the packages
        }
    }
} # To be completed with the rest of the packages

unload_SAARA_packages <- function(list_of_required_pckg)
{
    # Test if at least one argument is given to the function
    if (nargs() < 1) {
        stop("argument 'list_of_required_pckg' is missing, with no default.")
    }
    
    for ( i in 1:dim(list_of_required_pckg)[1])
    {
        detach(paste("package", list_of_required_pckg$pckg[i], sep = ":"), unload = TRUE, character.only = TRUE)
    }
    
    detach("package:devtools", unload = TRUE)
    detach("package:anyLib", unload = TRUE)
} # Ok but is it relevant ?

init_env <- function(list_of_required_pckg, wd)
{
    test <- load_SAARA_packages(list_of_required_pckg)
    
    check_SAARA_packages(list_of_required_pckg, test)
    
    setwd(wd)
} # OK ?





#### DATA EXTRACTION AND CALCULATIONS --------------------------------------------------------------------------------------------------------------------------------------------------------------

trim_file_path <- function(file_path)
{
    ## In a given string containing the path of a file or folder, 
    ## will trim the string ton anly keep the folder o file name. 
    ##
    ## Usage:
    ##          output <- trim_file_path(file_path)
    ##
    ## Input:
    ##      - file_path :       a string containing the path of the given file/folder
    ##
    ## Output:
    ##      - trimmed_string :  the string containning only the folder/file name. 
    
    if (nargs() <= 1)
    {
        
    }
    
    
    trimmed_string <- unlist(strsplit(file_path, '/'))[length(unlist(strsplit(file_path, '/')))]
    
    trimmed_string
} ## Ok<- not needed anymore


calculate_nmolC2H4_H_Plant <- function(pA_s, delta_time = 120, slope = 495, vial_volume = 21, splitV = 5, 
                                       customFormula = 0, nodule_weight = NULL, nodule_number = NULL)
{
    ## Function that calculates the nitrogenase activity in nmol of ethylene produced per hour and per plant
    ##
    ## Usage:
    ##          output <- calculate_nmolC2H4_H_Plant(pA_s, delta_time = 120, slope = 495, vial_volume = 21, splitV = 5, 
    ##                                               customFormula = 0, nodule_weight = c(), nodule_number = c())
    ##
    ## The default formula is:
    ##          nmolC2H4_H_Plant <- ( pA_s / delta_time ) * ( vial_volume / slope ) * 60 * splitV
    ## Input:
    ##      - pA_s :            raw data from the machine (pA.s-1)
    ##
    ##      - delta_time :      the difference between time when the sample is injected into the column and the time when sample is incubated with 
    ##                          acetylene (in minutes)
    ##
    ##      - slope :           OPTIONNAL, slope of the standard curve, allows to correlated mol of produced ethylene to the pA.s-1
    ##                          the standard curve should be established by injecting known quantities of ethylene into the GC-FID (default 495)
    ##
    ##      - vial volume :     OPTIONNAL, used in the calculations, can be modified if the experimentator measures the remaining volume in the vials
    ##                          this is generally used when plants occupy a big part of the vial volume (in mL ; default 21)
    ##
    ##      - splitV :           OPTIONNAL, specifies the value of the split factor. Necessary if the GC-FID method is using the split parameter.
    ##                          This parameter is used to reduce the quantity of sample injected in the column to avoid saturation.
    ##                          This script was designed to fit the method used in the GC-FID. In our case, the headspace fees 1 mL of the sample.
    ##                          If the split option is activated, then only a fifth of this 1 mL will be injected in the column (so 200 µL)
    ##                          To use this script with method that were designed differently, the value of split can be changed to fit the real 
    ##                          volume of sample injected.
    ##
    ##      - customFormula :   OPTIONNAL, a formula used to make the calculations. This option should be used carrefully as it can esaly lead to errors.
    ##                          Default is set to 0. This value is used as in a test for the programm to use the default formula.
    ##
    ## Outout:
    ##      - nmolC2H4_H_Plant: a double variable containing the processed value.
    
        # Test if at least one argument is given to the function
    if (nargs() < 1) {
        stop("argument 'pA_s' is missing, with no default.")
    }

        # The following test allows to change the formula if the user wants to.
    if (customFormula == 0)
    {
        formula <- "(( pA_s / delta_time ) * (vial_volume / slope) * 60 * splitV)"
        
        if (length(nodule_number != 0) & length(nodule_weight != 0))
        {
            #error
            print("ERROR: Both nodules number and nodule weight where given. Will not normalise.")
        }
        else
        {
            if (length(nodule_number != 0))
            {
                formula <- paste(formula, "/ ", nodule_number)
            }  
            if (length(nodule_weight != 0))
            {
                formula <- paste(formula, "/ ", nodule_weight)
            }
        }
    }
    else
    {
        formula <- customFormula
    }

        # Evaluate the expression
    nmolC2H4_H_Plant <- eval(parse(text = formula))

        # Return the output nmolC2H4_H_Plant
    nmolC2H4_H_Plant
} ## Ok <- error assertion has to be improved


calculation <- function(extracted_data, slope = 495, vial_volume = 21, splitV = 5, custom_formula = 0)
{
    ## Function that format data and stores converts the raw values into the processed data using calculate_nmolC2H4_H_Plant
    ##
    ## Usage:
    ##          output <- calculation(extracted_data, slope, vial_volume, splitV, customFormula)
    ##
    ## Input:
    ##      - extracted_data :  a data frame that contains the following data, in the same order:
    ##          - condition name (a string)
    ##          - sample ID, within a condition (integers)
    ##          - time_start_incubation : time when acetylene is infected into vials (hours & minutes on a different element of the data.frame))
    ##          - injection_ime : time when the sample is injected into the column (hours & minutes on a different element of the data.frame))
    ##          - pA_s : raw data from the machine (pA.s-1)
    ##          - nodule number : optionnal data that can be added to the analysis if needed (integers)
    ##          - nodule weight :  optionnal data that can be added to the analysis if needed (in mg)
    ##
    ##
    ##      - slope :           Slope of the standard curve, allows to correlated mol of produced ethylene to the pA.s-1
    ##                          the standard curve should be established by injecting known quantities of ethylene into the GC-FID (default 495)
    ##
    ##      - vial_volume :     Used in the calculations, can be modified if the experimentator measures the remaining volume in the vials
    ##                          this is generally used when plants occupy a big part of the vial volume (in mL ; default 21)
    ##
    ##      - splitV :           Specifies the value of the split factor. Necessary if the GC-FID method is using the split parameter.
    ##                          This parameter is used to reduce the quantity of sample injected in the column to avoid saturation.
    ##                          This script was designed to fit the method used in the GC-FID. In our case, the headspace fees 1 mL of the sample.
    ##                          If the split option is activates, then only a fifth of this 1 mL will be injected in the column (so 200 µL)
    ##                          To use this script with method that were designed differently, the value of split can be changed to fit the real 
    ##                          volume of sample injected.
    ##
    ##      - custom_formula :   OPTIONNAL, a formula used to make the calculations. This option should be used carrefully as it can esaly lead to errors.
    ##                          Default is set to 0. This value is used as in a test for the programm to use the default formula.
    ##
    ## Output:
    ##      - list_of_values :  a data.frame that contains :
    ##                              - condition_name (see the input extracted_data)
    ##                              - sample_id (see the input extracted_data)
    ##                              - nmolC2H4_H_Plant: the processed data.
    
    # Test if at least one argument is given to the function
    if (nargs() < 1) {
        stop("argument 'extracted_data' is missing, with no default.")
    }
    
        # Create a data.frame that will contain the processed data
    list_of_values <- data.frame(condition_name = extracted_data[,1], sample_id = extracted_data[,2], 
                                 nmolC2H4_H_plant = rep(0, times = dim(extracted_data)[1]))

        # Loop that will go through every sample in the extracted_data data.frame and use the function calculate_nmolC2H4_h_plant to process the data.
    for (i in 1:dim(extracted_data)[1])
    {
        delta_time <- (extracted_data[[i,6]] + extracted_data[[i,5]]*60) - (extracted_data[[i,4]] + extracted_data[[i,3]]*60)
        list_of_values[i,3] = calculate_nmolC2H4_H_Plant(pA_s = extracted_data[i,7], delta_time, slope, vial_volume, splitV, custom_formula, nodule_weight = c(), nodule_number = c())
    }
        
        # Return the list_of_values
    list_of_values
} ## Ok <- nodule nbr/mass have to be implemented as well as vial_volume + must improve output


get_tree_path <- function(pathToExpeFolder)
{
    ## Function that extract the path of each subfolder of every experiments
    ##
    ## Usage:
    ##          output <- get_tree_path(pathToxpeFolder)
    ##
    ## Input:
    ##      - pathToExpeFolder :    the name of the folder containing the data
    ##
    ## Output:
    ##      -sample_folders :       a data.frame containing the name of the folders of each samples in every experiment. 
    ##                              Each column of the data.frame is named after the experience folder.
    
    # Test if the argument is given to the function
    if (nargs() < 1) {
        stop("argument 'pathToExpeFolder' is missing, with no default.")
    }
    
        # List all experiment folders.
    expe_folder <- list.dirs(pathToExpeFolder, recursive = FALSE, full.names = FALSE)
        
        # Create the data.frame that will contain all the sample names of all experiments in the expeFolder.
    sample_folders <- lapply(expe_folder, function(x) 0)
    names(sample_folders) <- expe_folder
        
        # Loop that goes through expe_folder to recover all the names of sample folders.
    for (i in 1:length(expe_folder))
    {
            # Get sample path
        sample_folders[[i]] <- list.dirs(paste(pathToExpeFolder, '/', expe_folder[[i]], sep = ""), recursive = FALSE, full.names = FALSE)
            # Removes the method folder.
        sample_folders[[i]] = sample_folders[[i]][-grep(".M", sample_folders[[i]])]
    }
    
        # Return output
    sample_folders
} ## Ok <- add strmatch to rmv unwanted folders and other stuff. (done I think)


data_extraction <- function(pathToExpeFolder, expected_peak_ret_time = 1.65)
{
    ## Function that extract the data from the tree.
    ## Based on the position of each peaks in our assays. May be different for other experimental designs (this function can be improved).
    ## The peak that holds the highest value in measured retention time corresponds to acetylene in our experiemental design.
    ## It is preceeded by the ethylene peak and before that a 'contamination' peak (alaways present).
    ##
    ## Usage:
    ##          output <- data_extraction(pathToExpeFolder)
    ##
    ## Input:
    ##      - pathToExpeFolder :    the path to the folder containing the data
    ##
    ## Output:
    ##      - all_data :            a data.frame that contains all the required data.
    ##                                  - subfile_name : the name of the path from which the data was extracted
    ##                                  - sample_id : the name of the sample as given by the user before the run. 
    ##                                  - injection_time_H : hour of sample injection in the GC.
    ##                                  - injcetion_time_min : minutes of sample injection in the GC.
    ##                                  - ethylene_MeasRetTime : measured retention time.
    ##                                  - area : values of pA_s-1 measured by the FID.
    
    # Test if the argument is given to the function
    if (nargs() < 1) {
        stop("argument 'pathToExpeFolder' is missing, with no default.")
    }
    
        # Load readxl, and if not installed, install it.
    if (!require(readxl)) {
        warning("readxl was not installed prior to the use of this function. Latest version will be installed which could be incompatible wit the current environnment set-up.")
        install.packages("readxl")
        library(readxl)
    }
    
        # Get paths thanks to the get_tree_path function
    paths <- get_tree_path(pathToExpeFolder)
    
        # Prepare the list all_data
    all_data <- lapply(paths, function(x) 0)
    
        # For loop that goes through each experimment folders
    for (i in names(paths))
    {
            # Prepare a temporary data holder
        data <- data.frame(subfile_name=0, sample_id=0, injection_time_H=0, 
                           injection_time_min=0, ethylene_MeasRetTime=0, area=0)
        
            # For loop that goes through each sample folder
        for (j in paths[[i]])
        {
            temp_peak_data <- read_xls(paste(pathToExpeFolder, i, j, "REPORT01.xls", sep = '/'), sheet = "Peak")[,1:15] # Read data
            temp_peak_data$IntPeakType <- tidyr::replace_na(temp_peak_data$IntPeakType, 'a') # Remove Na and replace them by a
            temp_peak_data$HeaderName <- tidyr::replace_na(temp_peak_data$HeaderName, 'a') # Remove Na and replace them by a
            temp_peak_data$HeaderValue <- tidyr::replace_na(temp_peak_data$HeaderValue, 'a') # Remove Na and replace them by a.
            
            temp_peak_data[is.na(temp_peak_data)] <- 0 # Remove Na and replace them by zeros.
            
            #     # Identify the peak that holds the ethylene value, based on the measured retention time.
            # ratioRetTime <- temp_peak_data$MeasRetTime/max(temp_peak_data$MeasRetTime) # This makes a ratio between values of each 
            #                
            temp_base_info <- read_xls(paste(pathToExpeFolder, i, j, "REPORT01.xls", sep = '/'), sheet = "Sheet1") # Read info data
            
            test_name_variable <- c(is.na(temp_base_info[temp_base_info[,1]=="SampleName",2]), is.na(temp_base_info[temp_base_info[,1]=="SampleInfo",2]))
            
            # if (sum(is.nan(ratioRetTime)) == 0) {
            #                                                # peak and the max value of these values.
            #     pos <- which(ratioRetTime == 1)-1   # Get only the value before the acetylene
            #     while (temp_peak_data$MeasRetTime[pos] == 0) # Sometimes the predicted elution time of the different 
            #                                                  # compounds interfers with the measured elution time. To avoid that,
            #                                                  # this loop searches for the first value in the MeasRetTime that is different to zero.
            #     {
            #         pos = pos - 1
            #         if (pos == 1)
            #         {
            #             ## error
            #             break
            #         }
            #     }
            #     
            #     if (!test_name_variable[1]) {
            #         data <- rbind(data, c(paste(i, j, sep="/"), as.character(temp_base_info[temp_base_info[,1]=="SampleName",2]),
            #                               substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 12, stop = 13),
            #                               substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 15, stop = 16),
            #                               temp_peak_data$MeasRetTime[pos], temp_peak_data$Area[pos])) # Store everything into one data.frame
            #     }
            #     else if (!test_name_variable[2]) {
            #         data <- rbind(data, c(paste(i, j, sep="/"), as.character(temp_base_info[temp_base_info[,1]=="SampleInfo",2]),
            #                               substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 12, stop = 13),
            #                               substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 15, stop = 16),
            #                               temp_peak_data$MeasRetTime[pos], temp_peak_data$Area[pos])) # Store everything into one data.frame
            #     }
            #     else {
            #         stop("Cannot find sample names please be sure that sample names were correctly specified before the run")
            #     }
            # }
            # else {
            #     if (!test_name_variable[1]) {
            #         data <- rbind(data, c(paste(i, j, sep="/"), as.character(temp_base_info[temp_base_info[,1]=="SampleName",2]),
            #                               substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 12, stop = 13),
            #                               substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 15, stop = 16),
            #                               NA, NA)) # Store everything into one data.frame
            #     }
            #     else if (!test_name_variable[2]) {
            #         data <- rbind(data, c(paste(i, j, sep="/"), as.character(temp_base_info[temp_base_info[,1]=="SampleInfo",2]),
            #                               substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 12, stop = 13),
            #                               substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 15, stop = 16),
            #                               NA, NA)) # Store everything into one data.frame
            #     }
            #     else {
            #         stop("Cannot find sample names please be sure that sample names were correctly specified before the run")
            #     }
            # }
            
            find_closest_peak <- temp_peak_data$MeasRetTime - expected_peak_ret_time
            closest_peak <- which(abs(find_closest_peak) == min(abs(find_closest_peak)))
            
            if (!test_name_variable[1]) {
                data <- rbind(data, c(paste(i, j, sep="/"), as.character(temp_base_info[temp_base_info[,1]=="SampleName",2]),
                                      substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 12, stop = 13),
                                      substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 15, stop = 16),
                                      temp_peak_data$MeasRetTime[closest_peak], temp_peak_data$Area[closest_peak])) # Store everything into one data.frame
            }
            else if (!test_name_variable[2]) {
                data <- rbind(data, c(paste(i, j, sep="/"), as.character(temp_base_info[temp_base_info[,1]=="SampleInfo",2]),
                                      substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 12, stop = 13),
                                      substr(temp_base_info[temp_base_info[,1]=="InjDateTime",2], start = 15, stop = 16),
                                      temp_peak_data$MeasRetTime[closest_peak], temp_peak_data$Area[closest_peak])) # Store everything into one data.frame
            }
            else {
                stop("Cannot find sample names please be sure that sample names were correctly specified before the run")
            }
        }
        data <- data[2:dim(data)[1],] # Trim the first row of the data.frame which only contains zeros
        all_data[[i]] <- data # Store the data frame in the all_data list.
    }
    
        # Detach package
    detach("package:readxl", unload = TRUE)
    
        # Return all_data
    all_data
} ## Ok


template_gen <- function(pathToExpeFolder, path_to_template)
{
    ## Function that formates the template data given as an excel file.
    ## The given file must be an .xls or .xlsx and must be present in the folder
    ## which path is given by pathToExpeFolder. The tables must not have headers.
    ## This file must carry one sheet per experiment, detailling for each sample the necessary data:
    ##              - The condition identifier of each sample used in the Agilent Software during the Easy Queue setting.
    ##              - condition_name : the identifier of the condition (name of the mutant, of the treatment, etc.)
    ##              - sample_number : the number of this sample within a given condition.
    ##              - incubation_hour : time when acetylene was injected in the vials (hours).
    ##              - incubation_minutes : time when acetylene was injected in the vials (minutes).
    ##                      For example, if the incubation of the first sample began at 14:35,
    ##                      incubation_hour of the first line would be 14 and incubation_minutes would be 35.
    ##                  This for all experiments
    ##
    ## Usage:
    ##          output <- template_gen(pathToExpeFolder, path_to_template)
    ##
    ## Inputs:
    ##      - pathToExpeFolder : the path to expe folders
    ##
    ##      - path_to_template : the path to find the excel file
    ##
    ## Output:
    ##      - template : data.frame aving the same composition as the excel file
    
    # Test if the arguments are given to the function
    if (nargs() < 2) {
        stop("arguments 'pathToExpeFolder' or/and 'path_to_template' are missing, with no default.")
    }
    
        # Load readxl, and if not installed, install it.
    if (!require(readxl)) {
        warning("readxl was not installed prior to the use of this function. Latest version will be installed which could be incompatible wit the current environnment set-up.")
        install.packages("readxl")
        library(readxl)
    }
    
        # Generate the template list
    expe_names <- list.dirs(pathToExpeFolder, full.names = FALSE, recursive = FALSE)
    template <- lapply(expe_names, function(x) 0)
    names(template) <- expe_names
        
        # Loop that goes through each of the sheets of the template excel file and stores it into the template list
    for (i in 1:length(template))
    {
        template[[i]] <- read_excel(path_to_template, sheet = i, col_names = FALSE)
    }
    
        # Detach package
    detach("package:readxl", unload = TRUE)
    
        # Return template
    template
} ## Ok


data_formating_and_calc <- function(all_data, template)
{
    ## Takes the all_data data.frame generated from the data_extraction function.
    ## Returns processed extracted_data which will be used for the calculations.
    ## Calls 
    ##
    ## Usage:
    ##          output <- data_formating_and_calc(all_data, template)
    ##
    ## Inputs:
    ##      - all_data : data.frame containing output data from the data_extraction function
    ##
    ##      - template : a data.frame carring:
    ##              - The condition identifier used in the Agilent Software during the Easy Queue setting.
    ##              - condition_name :      the identifier of the condition (name of the mutant, of the treatment, etc.)
    ##              - sample_number :       the number of this sample within a given condition.
    ##              - incubation_hour :     time when acetylene was injected in the vials (hours).
    ##              - incubation_minutes :  time when acetylene was injected in the vials (minutes).
    ##                      For example, if the incubation of the first sample began at 14:35,
    ##                      incubation_hour of the first line would be 14 and incubation_minutes would be 35.
    ##              - vial_volume :         the volume of the vial in mL
    ##                  This for all experiments
    ##
    ## Output:
    ##      - result_data : a list that carries, in each of its elements (experiences) a data.frame that contains:
    ##              - condition_name
    ##              - sample_number
    ##              - nmolC2H4_H_Plant : values of processed data.
    
    # Test if the arguments are given to the function
    if (nargs() < 2) {
        stop("arguments 'all_data' or/and 'template' are missing, with no default.")
    }
    
        # Generate the output data.frame
    result_data <- lapply(names(all_data), function(x) 0)
    names(result_data) <- names(all_data)
    
        # For loop that goes through each experiment
    for (i in names(all_data))
    {
            # generate the data.frame that will hold the formated data for the calculation
        extracted_data <- data.frame(condition_name = as.character(rep("", times = dim(all_data[[i]])[1])), 
                                     sample_number = rep(0, times = dim(all_data[[i]])[1]), 
                                     incubation_hour = rep(0, times = dim(all_data[[i]])[1]), 
                                     incubation_minutes = rep(0, times = dim(all_data[[i]])[1]), 
                                     injection_hour = as.numeric(unlist(all_data[[i]]["injection_time_H"])), 
                                     injection_minutes = as.numeric(unlist(all_data[[i]]["injection_time_min"])), 
                                     pA_s = as.numeric(unlist(all_data[[i]]["area"])), nodule_number = 0, nodule_weight = 0, 
                                     stringsAsFactors = FALSE)
        
            # Recover data from the template data and assign it to the correct row in extraced_data
        for (j in 1:dim(template[[i]])[1])
        {
            # Assign data to extracted_data
            extracted_data[j, "condition_name"] <- unlist(template[[i]][j,2])
            extracted_data[j, "sample_number"] <- unlist(template[[i]][j,3])
            extracted_data[j, "incubation_hour"] <- as.numeric(unlist(template[[i]][j,4]))
            extracted_data[j, "incubation_minutes"] <- as.numeric(unlist(template[[i]][j,5]))
        }
        
        
        result_data[[i]] <- calculation(extracted_data, slope = 495, vial_volume = 21, splitV = 5, custom_formula = 0)
    }   
    
        # Return extracted_data
    result_data
} ## Ok add vial_volume in the pipeline as well as nodule mass


write_data <- function(result_data, save_path)
{
    ## Save the results into one excel file. Maybe not usefull, depends on how much the Qt App can be linked with this script.
    ##
    ## Usage:
    ##          output <- write_data(result_data, save_path)
    ##
    ## Input:
    ##      - result_data : list of data.frame generated by the data_formating_and_calc function.
    ##
    ##      - save_path : the path to the saved file.
    ##
    ## Output:
    ##      - none : this function should only save the data and return nothing
    
    # Test if the arguments are given to the function
    if (nargs() < 2) {
        stop("arguments 'result_data' or/and 'save_path' are missing, with no default.")
    }
    
    # Load xlsx, and if not installed, install it.
    if (!require(xlsx)) {
        warning("xlsx was not installed prior to the use of this function. Latest version will be installed which could be incompatible wit the current environnment set-up.")
        install.packages("xlsx")
        library(xlsx)
    }
    
        # Check the presence of the file
    if (!file.exists(save_path))
    {
        for (i in names(result_data))
        {
            write.xlsx(result_data[[i]], save_path, sheetName = i, append = TRUE)
        }    
    }
    else
    {
        print("File already exist.")
    }
    
    detach("package:xlsx", unload = TRUE)
    
} ## Ok <- overwrite to be reviewed


remove_controls <- function(results)
{
    # Test if the argument is given to the function
    if (nargs() < 1) {
        stop("argument 'results' is missing, with no default.")
    }
    
    trimmed <- lapply(results, names)
    for (i in 1:length(names(results)))
    {
        trimmed[[i]] <- results[[i]][-which(results[[i]][,1] == "control"),]
        
    }
    trimmed
} ## Ongoing


pool_expe <- function(results, pooling_ref, template)
{
    # Test if the argument is given to the function
    if (nargs() < 2) {
        stop("arguments 'results' and/or 'pooling_ref' are missing, with no default.")
    }
    
    pooled_results <- lapply(pooling_ref, names)
    pooled_temp <- lapply(pooling_ref, names)
    
    for (i in names(pooling_ref)) {
        for (j in pooling_ref[[i]]) {
            pooled_results[[i]] <- rbind(pooled_results[[i]], results[[j]])
            pooled_temp[[i]] <- rbind(pooled_temp[[i]], template[[j]])
        }
    }
    all_pooled <- list(pooled_results, pooled_temp)
    
    all_pooled
} ## To Do

merge_reorganize_lists <- function(l1, l2, names = NULL)
{
    if (nargs() < 2)
        stop("arguments 'l1' and/or 'l2' are missing, with no default.")
    
    if (length(l1) != length(l2))
        stop("Lists must be of the same length.")
    
    output_list <- lapply(l1, names)
    
    for (i in names(l1)) {
        output_list[[i]] <- list(l1[[i]], l2[[i]])
        
        if (!is.null(names))
            names(output_list[[i]]) <- names
    }
    
    return(output_list)
}

#### STATISTICAL ANALYSIS --------------------------------------------------------------------------------------------------------------------------------------------------------------

check_normality <- function(result, normalityThreshold = 0.05)
{
    ## Testing for normality to perform FTest
    ##
    ## Usage:
    ##          output <- check_normality(result, normalityThreshold)
    ##
    ## Input:
    ##      - result :              the list generated by the remove_controls function
    ##
    ##      - normalityThreshold :  a single integer value that gives the threshold for the false 
    ##                              positive rate or probability of type I error (default 0.05).
    ##
    ## Output:
    ##      - test_result :         a list which length equals the number of experiments. For each of its elements, this list contains a list of two vectors:
    ##              - p_values :        the p.value of the test for each condition.
    ##
    ##              - boolean_result :  the result of the test transformed into boolean values.
    ##                                  Based on the threshold given as second input.
    
    # Test if the argument is given to the function
    if (nargs() < 1) {
        stop("argument 'result' is missing, with no default.")
    }
    
    expeNbr <- length(names(result))
    
    s_w_results <- lapply(result, function(x) 0)
        # Loop that goes through every experiment
    
    for (i in 1:expeNbr)
    {
        
        condNames <- levels(as.factor(result[[i]][,"condition_name"]))
        
        testSW <- rep(0, times = length(condNames))
        isNormal <- rep(0, times = length(condNames))
        
        names(testSW) <- names(isNormal) <- condNames
        
            # Loop that goes through every conditions of the current experiment.
        for (j in 1:length(condNames))
        { ##scan conditions to determine normality of each data subset
            indices <- grep(condNames[j], result[[i]][,"condition_name"], fixed = TRUE)
            
                # If the size of the sample is smaller that 3, the the test cannot be performed.
                # The value of 2 is assigned to this condition as it is an impossible value of the p-value.
                # Used for testing later-on, and  to distinguished these conditions from non-normal samples.
            if (length(indices) < 3)
                testSW[j] <- 2
            
                # Otherwise, perform the satistical test.
            else
                testSW[j] <- shapiro.test(result[[i]][indices, "nmolC2H4_H_plant"])$p.value
            
                # Assign a boolean value depending on the result of the test.
            if (testSW[j] >= normalityThreshold)
                isNormal[j] <- TRUE
            
            else 
                isNormal[j] <- FALSE
            
                # NA is for samples which have been associated with the value 2.
            if (testSW[j] == 2)
                isNormal[j] <- NA
        } 
        s_w_results[[i]] <- list(p_values = testSW, boolean_result = isNormal)
    }
    
        # Return s_w_results
    s_w_results
} ## Ok

check_var_h <- function(result, varHThreshold = 0.05)
{
    ## F-test : Testing variance homescedasticity
    ##
    ## Usage:
    ##          output <- check_var_h(result, varHThreshold = 0.05)
    ##
    ## Inputs:
    ##      - result :          the list as generated by the remove_controls function
    ##
    ##      - varHThreshold :   a single integer value that gives the threshold for the false 
    ##                          positive rate or probability of type I error (default 0.05).
    ##
    ## Outut:
    ##      - varH :            a list for which each element is related to an experiment. For each of its elements, 
    ##♣                         this list contains a list of two matrixes:
    ##              - p_values :        the p.value of the test for each combination of condition.
    ##
    ##              - boolean_result :  the result of the test transformed into boolean values.
    ##                                  Based on the threshold given as second input.
    
    # Test if the argument is given to the function
    if (nargs() < 1) {
        stop("argument 'result' is missing, with no default.")
    }
    
    expeNbr <- length(names(result))
    
    varH <- lapply(result, function(x) 0)
    
    for (i in 1:expeNbr) 
    { ##Loop for experiments scannin
        condNames <- levels(as.factor(result[[i]][,"condition_name"]))
        
        ## A CAHNGER FAIRE DES MATRICES a stocker dans un data Frame
        temp_val <- list(p_values = 0, boolean_results = 0)
                               
        p_values <- matrix(NA, nrow = length(condNames), ncol = length(condNames))
        bool_vals <- matrix(NA, nrow = length(condNames), ncol = length(condNames))
        rownames(p_values) <- rownames(bool_vals) <- colnames(p_values) <- colnames(bool_vals) <- condNames
        
        all_comb <- do.call(c, lapply(seq_along(condNames), combn, x = condNames, simplify = FALSE))
        
            # Go though every possible combination
        for (j in all_comb)
        {
                # Remove the combination of elements that involve a number of element different from 2
            if (length(j) == 2)
            {
                    # Verify that the combination has not been tested yet
                if (is.na(p_values[j[1], j[2]]) && is.na(p_values[j[2], j[1]]))
                {
                    if (sum(result[[i]][,1] == j[1]) > 3 && sum(result[[i]][,1] == j[2]) > 3)
                    {
                        p_values[j[1], j[2]] <- var.test(result[[i]][result[[i]][,1] == j[1],"nmolC2H4_H_plant"], 
                                                         result[[i]][result[[i]][,1] == j[2],"nmolC2H4_H_plant"])$p.value
                    }
                    else
                        p_values[j[1], j[2]] <- 2
                    
                    ## Then tests bool
                    if (p_values[j[1], j[2]] >= varHThreshold)
                        bool_vals[j[1], j[2]] <- TRUE
                    
                    else 
                        bool_vals[j[1], j[2]] <- FALSE
                    
                    if (p_values[j[1], j[2]] == 2)
                        bool_vals[j[1], j[2]] <- NA
                }
            }
        }
        temp_val[[1]] <- p_values
        temp_val[[2]] <- bool_vals
        
        varH[[i]] <- temp_val
    }
     
    varH
} ## Ok

check_means <- function(result, normality_results, var_h_results, threshold = 0.05)
{
    ## Testing means of the samples
    ## This function chooses the appropriate test according to the results of the Shapiro-Wilks and F-test results
    ##
    ##  Usage:
    ##          output <- check_means((result, normality_results, var_h_results)
    ##
    ## Inputs:
    ##      - result :              a list containing processed results of the ARA experiment as generated by the
    ##                              data_formating_and_calc fucntion. Each element of the list correspond to one experiment
    ##                              in the tree and carries a data.frame containing all necessary informations from the analysis:
    ##                                  - condition_name
    ##                                  - sample_number
    ##                                  - the value of nmolC2H4_H_plant
    ##
    ##      - normality_results :   results generated by the fuction check_normality, which performs a Shapiro-Wilks test,
    ##                              a list in which each elements is related to an experiment and contins a list of two elements:
    ##                                  - p_values :        p.values calculated after a Shapiro-Wilks test.
    ##                                  - boolean_values :  determined according to threshold given as input of the check_normality function.
    ##
    ##      - var_h_results :       results generated by the fuction check_var_h, which verifies the variance homoscedasticity of each 
    ##                              pair of conditions within an experiment. This variable should be a list in which each elements 
    ##                              is related to an experiment and contins a list of two elements:
    ##                                  - p_values :        p.values calculated after a F-test.
    ##                                  - boolean_values :  determined according to threshold given as input of the check_var_h function.
    ##
    ## Ouput:
    ##      - means_analysis :      a list containing for each experiment: 
    ##                                  - test_performed : the name of the test used by the function to verify the means
    ##                              Then, the format of the list depends on the test performed:
    ##                              If the test was an ANOVA:
    ##                                  - 
    ##
    ##                              If the test was a one-way (welch corrected t-test):
    ##                                  -
    ##
    ##                              If the test was a Kruskal-Wallis
    ##                                  - 
    
    
    # Test if the arguments are given to the function
    if (nargs() < 3) {
        stop("arguments 'result' or/and 'normality_results' or/and 'var_h_results' is missing, with no default.")
    }
    
    
    if (!require(car)) {
        warning("car was not installed prior to the use of this function. Latest version has been installed which could be incompatible wit the current environnment set-up.")
        install.packages('car')
        library(car)
    }
    
    if (!require(dunn.test)) {
        warning("dunn.test was not installed prior to the use of this function. Latest version has been installed which could be incompatible wit the current environnment set-up.")
        install.packages('dunn.test')
        library(dunn.test)
    }
    
    mean_test <- list()
    
    for (i in names(result))
    {
        condNames <- levels(as.factor(result[[i]]$condition_name))
        combNbr <- length(combn(length(condNames), 2))/2
        
        if (sum(normality_results[[i]]$boolean_result, na.rm = TRUE) == length(condNames))
        {
            print("All variables have a normal distribution.")
            if (sum(var_h_results[[i]]$boolean_results, na.rm = TRUE) == combNbr)
            {
                print("Variables are homoscedastic.")
                #Graph
                #par(mar=rep(2,4)) #marge des valeurs
                #boxplot(result[[i]]$nmolC2H4_H_plant ~ as.factor(result[[i]]$condition_name), ylab = "nmolC2H4.h.plant")
                
                # linear model for anova
                anova_model <- lm(result[[i]]$nmolC2H4_H_plant ~ as.factor(result[[i]]$condition_name), data = result[[i]] )
                
                # Graphics Verification of residues normality
                        # oldpar <- par(mar = rep(2,4), oma = rep(2,4), mfrow = c(2,2))
                pdf(file = paste(pathToExpeFolder, "/qqplot_anova_", gsub(" ", "_", names(result)[i]), ".pdf", sep = ""))
                print(plot(anova_model))
                        # par(oldpar)
                print(qqPlot(anova_model, simulate = TRUE, id.method = "y", id.n = 2, main = "Q-Q plot with confidence enveloppe"))
                dev.off()
                
                # Verify residues normality
                res <- anova_model$residuals
                resNorm <- numeric()
                isResNorm <- logical()
                
                for (j in 1:length(condNames))
                {
                    resNorm[j] <- shapiro.test(res[which(result[[i]]$condition_name == condNames[j])])$p.value
                    if (resNorm[j] >= normalityThreshold)
                    {
                        isResNormal[j] <- TRUE          
                    }
                }
                
                # AnOVa
                Anova(anova_model, type = 2)
                
                mean_test[[i]] <- TukeyHSD(aov(result[[i]]$nmolC2H4_H_plant ~ as.factor(result[[i]]$condition_name), data = result[[i]] ), conf.level = 1-threshold)
                print(plot(mean_test[[i]]))
                
            }
            else
            {
                print("Variables are heteroscedastic.")
                #correction de welch (oneway.test ; var not H) + dunn test as a post-hoc test ? add the loading of the "dunn.test" package
                    #kruskal.test(nmolArray[,i] ~ as.factor(allData[,"Name",i]))
                oneway.test(nmolArray[,i] ~ as.factor(allData[,"Name",i]), var.equal = FALSE)
                
                mean_test[[i]] <- TukeyHSD(aov(result[[i]]$nmolC2H4_H_plant ~ as.factor(result[[i]]$condition_name), data = result[[i]] ), conf.level = 1-threshold)
                print(plot(mean_test[[i]]))
                
            }
        }
        else
        {
            #kruslal-wallis + dunn test as a post-hoc test ? add the loading of the "dunn.test" package
            mean_test[[i]] <- dunn.test(x = result[[i]]$nmolC2H4_H_plant, g = as.factor(result[[i]]$condition_name), alpha = threshold)
        }
    }
    
        # Detach package
    detach("package:car", unload = TRUE)
    ##    * 0.05     ** 0.01      *** 0.001
    
    return(mean_test)
} # Ongoing // move the package loading in the right test so not all packages are loaded at the beginning of the function.s


#### GRAPHICAL REPRESENTATION --------------------------------------------------------------------------------------------------------------------------------------------------------------

##Include GGplot2, look for violin plots to represent the ARA results.

reference_condition <- function(result_ref) 
{
    if (nargs() < 1) {
        stop("argument 'result_ref' is missing, with no default.")
    }
    
    x <- c()
    y <- c()
    
    for (i in 1:dim(result_ref$result)[1]) {
        x[i] <- result_ref$ref[which(result_ref$ref == result_ref$result$condition_name[i]),2]
        y[i] <- result_ref$ref[which(result_ref$ref == result_ref$result$condition_name[i]),3]
        
    }
    result_ref$result <- cbind(result_ref$result, class = x)
    result_ref$result <- cbind(result_ref$result, ord = as.numeric(y))
    
    return(result_ref)
}

assign_facet_classes <- function(result, path_to_ref) 
{
    if (nargs() < 2) {
        stop("at least one argument ('result' and/or 'path_to_ref' is missing.")
    }
    
    if (!require(openxlsx)) {
        warning("openxlsx was not installed prior to the use of this function. Latest version has been installed which could be incompatible wit the current environnment set-up.")
        install.packages('openxlsx')
        library(openxlsx)
    }
    
    ref <- lapply(result, names)
    
    for (i in names(ref)) {
        ref[[i]] <- read.xlsx(path_to_ref, sheet = i)
    }
    
    result <- lapply(merge_reorganize_lists(result, ref, c("result", "ref")), reference_condition)
    
    for (i in names(result))
        result[[i]] <- result[[i]]$result
    
    return(result)
}

get_high_values <- function(x, lim)
{
    if (nargs() < 2) {
        stop("at least one argument is missing ('x' and/or 'lim'), with no default.")
    }
    
    y <- as.data.frame(table(x[which(x$nmolC2H4_H_plant > lim),"condition_name"]))
    if (dim(y)[1] != 0) {
        colnames(y) <- c("condition_name", "nmolC2H4_H_plant")
        y$nmolC2H4_H_plant <- gsub( "[0-9]", 0.5, y$nmolC2H4_H_plant)
    }
    else
        y <- NULL
    
    return(y)
}

trim_data_4_graphs <- function(data, lim) 
{
    if (nargs() < 2) {
        stop("at least one argument is missing ('data' and/or 'lim'), with no default.")
    }
    
    data <- data[!is.na(data$nmolC2H4_H_plant),]
    data <- data[!(data$nmolC2H4_H_plant >= lim),]
    
    return(data)
}

get_stat_lab <- function(res) 
{
    if (nargs() < 1) {
        stop("argument 'res' is missing, with no default.")
    }
    
    if (!require(multcompView)) {
        warning("multcompView was not installed prior to the use of this function. Latest version has been installed which could be incompatible wit the current environnment set-up.")
        install.packages('multcompView')
        library(multcompView)
    }
    
    if (!require(plyr)) {
        warning("plyr was not installed prior to the use of this function. Latest version has been installed which could be incompatible wit the current environnment set-up.")
        install.packages('plyr')
        library(plyr)
    }
    
    names(res$stat$P.adjusted) <- gsub(" ", "", res$stat$comparisons)
    assigned_class <- multcompLetters(res$stat$P.adjusted)["Letters"]
    condition_name <- names(assigned_class[["Letters"]])
    
    boxplot.df <- ddply(res$result, .(condition_name), function(x) max(fivenum(x$nmolC2H4_H_plant)+0.1*(x$nmolC2H4_H_plant)+300, na.rm = TRUE))
    #boxplot.df <- boxplot.df[, c("condition_name", "V1")]
    plot.levels <- data.frame(condition_name, labels = assigned_class[['Letters']],
                              stringsAsFactors = FALSE)
    
    labels.df <- merge(plot.levels, boxplot.df, by= "condition_name", sort = FALSE)
    
    return(labels.df)
}

gen_stat_lab <- function(result, stats)
{
    if (nargs() < 2) {
        stop("at least one argument ('result' and/or 'stats' is missing.")
    }
    
    labels <- lapply(merge_reorganize_lists(stats, result, c("stat", "result")), get_stat_lab)
    labels_ref <- lapply(merge_reorganize_lists(labels, ref, c("results", "ref")), reference_condition)
    
    for (i in names(labels_ref))
        labels_ref[[i]] <- labels_ref[[i]]$result
    
    return(labels_ref)  
}

do_the_plot <- function(result, y_axis_title = "", y_axis_text_size = 20, box_width = 1.5, stats = NULL, colors = NULL, facet = FALSE) 
{
    if (nargs() < 1) {
        stop("argument 'result' is missing.")
    }
    
    if (!require(ggplot2)) {
        warning("ggplot2 was not installed prior to the use of this function. Latest version has been installed which could be incompatible wit the current environnment set-up.")
        install.packages('ggplot2')
        library(ggplot2)
    }
    
    if (!require(tidytext)) {
        warning("tidytext was not installed prior to the use of this function. Latest version has been installed which could be incompatible wit the current environnment set-up.")
        install.packages('tidytext')
        library(tidytext)
    }
    
    
    the_plot <- ggplot(result, aes(x = reorder_within(condition_name, ord, class), y = nmolC2H4_H_plant, fill = condition_name)) +
                geom_boxplot(size = box_width)
    
    if (facet == TRUE)
        the_plot <- the_plot + facet_grid(~class, scales = "free") 
    
    if (!is.null(colors))
        the_plot <- the_plot + scale_fill_manual(values = colors)
    
    the_plot <- the_plot +
                scale_x_reordered() +
                labs(x = "", y = y_axis_title) +
                theme(legend.position = "none",
                      strip.text = element_text(size = y_axis_text_size + 4, face = "bold"),
                      axis.title.y = element_text(size = y_axis_text_size + 2),
                      axis.text.y = element_text(size = y_axis_text_size))
    if (!is.null(stats)) 
        the_plot <- the_plot + geom_text(data = stats, aes(x = reorder_within(condition_name, ord, class), y = V1, label = labels), size = 8)
    
    return(the_plot)
}

save_bmp <- function(plots, awidth = 1000, aheight = 850, unit = "px") 
{
    while (!is.null(dev.list()))  dev.off()
    
    for ( i in 1:length(plots)) {
        bmp(file = paste(names(plots)[i], ".bmp", sep = ""), width = awidth, height = aheight, units = unit)
        print(plots[[i]])
        dev.off()
    }
}

save_jpg <- function(plots, awidth = 1000, aheight = 850, unit = "px", quality = 75) 
{
    while (!is.null(dev.list()))  dev.off()
    
    for ( i in 1:length(plots)) {
        jpeg(file = paste(names(plots)[i], ".jpeg", sep = ""), width = awidth, height = aheight, units = unit, quality = quality)
        print(plots[[i]])
        dev.off()
    }
}

save_png <- function(plots, awidth = 1000, aheight = 850, unit = "px") 
{
    while (!is.null(dev.list()))  dev.off()
    
    for ( i in 1:length(plots)) {
        png(file = paste(names(plots)[i], ".png", sep = ""), width = awidth, height = aheight, units = unit)
        print(plots[[i]])
        dev.off()
    }
}

save_tiff <- function(plots, awidth = 1000, aheight = 850, unit = "px", compression = 'none') 
{
    while (!is.null(dev.list()))  dev.off()
    
    for ( i in 1:length(plots)) {
        tiff(file = paste(names(plots)[i], ".tiff", sep = ""), width = awidth, height = aheight, units = unit, compression = compression)
        print(plots[[i]])
        dev.off()
    }
}

save_pdf <- function(plots, awidth = 1000, aheight = 850, unit = "px", compression = 'none') 
{
    while (!is.null(dev.list()))  dev.off()
    
    for ( i in 1:length(plots)) {
        pdf(file = paste(names(plots)[i], ".pdf", sep = ""), width = awidth, height = aheight, units = unit)
        print(plots[[i]])
        dev.off()
    }
}

#### SAARA R FUNCTIONS --------------------------------------------------------------------------------------------------------------------------------------------------------------

saara_raw_data <- function()
{
    
}

saara_calculations <- function()
{
    
}

saara_stats <- function()
{
    
}

saara_plots <- function(result, format, y_axis_title, y_axis_text_size = 20, box_width = 1.5, stats = NULL, colors = NULL, facet = FALSE, graph_width = 1000, graph_height = 850, graph_unit = 'px', jpg_quality = 75, tiff_pdf_compression = 'none') 
{
    plots <- lapply(result, names)
    
    for (i in names(plots)) {
        plots[[i]] <- do_the_plot(result[[i]], y_axis_title = y_axis_title, y_axis_text_size = y_axis_text_size, box_width = box_width, stats = stats[[i]], colors = colors, facet = facet)
    }
    
    switch(format,
           bmp = save_bmp(plots, awidth = graph_width, aheight = graph_height, unit = graph_unit),
           jpg = save_jpg(plots, awidth = graph_width, aheight = graph_height, unit = graph_unit, quality = jpg_quality),
           png = save_png(plots, awidth = graph_width, aheight = graph_height, unit = graph_unit),
           tiff = save_tiff(plots, awidth = graph_width, aheight = graph_height, unit = graph_unit, compression = tiff_pdf_compression),
           pdf = save_pdf(plots, awidth = graph_width, aheight = graph_height, unit = graph_unit, compression = tiff_pdf_compression),
           stop("provided format does not match with the available format : bmp, jpg, png, tiff and pdf")
           )
}

saara <- function(pathToTemplate, pathToData, doStats = FALSE, statThresholdVar = 0.5, statThresholdNorm = 0.5, doGraphics = FALSE, colors = NA, splitFact = 5, vialVolume = 21, slope = 495)
{
    
} # To be done





#### CODE TESTING ---------------------------------------------------------------------------------------------------------------------------------------------------------------

list_of_required_pckg <- data.frame(pckg = c("readxl", "xlsx", "car", "testit", "RInside"),
                                    version = c("1.3.1", "0.6.1", "3.0-2", "0.9", "0.2.15")) ## needs tidyr, plyr and multcompView also

pooling_ref <- list(Mt = c(1:6), Ms = c(7:11))

pathToExpeFolder <- "C:/Users/quent/Desktop/arayej"

init_env(list_of_required_pckg, pathToExpeFolder)

pathToTemplate <- paste(getwd(), "/temp2.xlsx", sep = "")

extract <- data_extraction(getwd(), 1.65)
temp <- template_gen(getwd(), pathToTemplate)

pool_all <- pool_expe(extract, pooling_ref, temp)

##Temp / spe to yejara expe
clean_table <- function(pool_extract) {
    mtNi <- pool_extract[[2]][seq(from = 112, to = 120, by = 2),]
    pool_extract[[1]] <- rbind(pool_extract[[1]], mtNi)
    pool_extract[[2]] <- pool_extract[[2]][-seq(from = 112, to = 120, by = 2),]

    pool_extract
}
pool_all <- lapply(pool_all, clean_table)


res <- data_formating_and_calc(pool_all[[1]], pool_all[[2]])

res <- remove_controls(res)

write_data(res, "C:/Users/quent/Desktop/arayej/results.xlsx")

result <- res

a <- check_normality(result)
normality_results <- a
b <- check_var_h(result)
var_h_results <- b

mean_test_res <- check_means(result, normality_results, var_h_results)





result <- assign_facet_classes(result, "reference.xlsx")

label_ok <- gen_stat_lab(result, mean_test_res)

saara_plots(result, "bmp", y_axis_title = "Nitrogen fixation (nmol(C2H4)/h/plant)", y_axis_text_size = 20, box_width = 1.5, stats = label_ok, colors = c("black", "#4CB4BE", "#93aa00", "grey", "#619cff", "white", "#FFBA00", "#FF9223", "#FF5123"), facet = TRUE, graph_width = 1100, graph_height = 500, graph_unit = 'px', jpg_quality = 75, tiff_pdf_compression = 'none') 


# plots <- list( Mt =
#     ggplot(result$Mt, aes(x = reorder_within(condition_name, ord, class), y = nmolC2H4_H_plant, fill = condition_name)) +
#     geom_boxplot(size = 1.5) +
#     facet_grid(~class, scales = "free") +
#     scale_x_reordered() +
#     scale_fill_manual(values = c("black", "#4CB4BE", "#93aa00", "grey", "#619cff", "white", "#FFBA00", "#FF9223", "#FF5123")) +
#     labs(x = "", y = "Nitrogen fixation (nmol(C2H4)/h/plant)") +
#     theme(legend.position = "none",
#           strip.text = element_text(size = 24, face="bold"),
#           axis.title.y = element_text(size = 22),
#           axis.text.y = element_text(size = 20)) + 
#     geom_text(data = label_ok$Mt, aes(x = reorder_within(condition_name, ord, class), y = V1, label = labels),size=8)
#              , Ms =
#     ggplot(result$Ms, aes(x = reorder_within(condition_name, ord, class), y = nmolC2H4_H_plant, fill = condition_name)) +
#     geom_boxplot(size = 1.5) +
#     facet_grid(~class, scales = "free") +
#     scale_x_reordered() +
#     scale_fill_manual(values = c("black", "#4CB4BE", "#93aa00", "grey", "#619cff", "white", "#FFBA00", "#FF9223", "#FF5123")) +
#     labs(x = "", y = "Nitrogen fixation (nmol(C2H4)/h/plant)") +
#     theme(legend.position = "none",
#           strip.text = element_text(size = 24, face="bold"),
#           axis.title.y = element_text(size = 22),
#           axis.text.y = element_text(size = 20)) + 
#     geom_text(data = label_ok$Ms, aes(x = reorder_within(condition_name, ord, class), y = V1, label = labels),size=8)
#     )
# 
# save_bmp(plots, awidth = 1100, aheight = 500)